{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building and registering the container\n",
    "\n",
    "The `build-and-push.sh` builds the container image using `docker build` and push the container image to ECR using `docker push`. \n",
    "\n",
    "If the `gpu` argument is passed to `build-and-push.sh` the GPU Docker file is used to create the GPU instance.  Otherwise the CPU instance is created.\n",
    "\n",
    "This code looks for an ECR repository in the account you're using and the current default region (if you're using a SageMaker notebook instance, this is the region where the notebook instance was created). If the repository doesn't exist, the script will create it. In addition, since we are using the SageMaker PyTorch image as the base, we will need to retrieve ECR credentials to pull this public image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requesting RL image\n",
      "Login Succeeded\n",
      "Login Succeeded\n",
      "Sending build context to Docker daemon  281.1kB\n",
      "Step 1/11 : ARG REGION=us-east-1\n",
      "Step 2/11 : FROM 763104351884.dkr.ecr.$REGION.amazonaws.com/pytorch-training:1.8.1-cpu-py36\n",
      " ---> 82ca317d0c5e\n",
      "Step 3/11 : RUN apt-get update && apt-get -y install cmake libopenmpi-dev zlib1g-dev\n",
      " ---> Using cache\n",
      " ---> fc5dcc3bc043\n",
      "Step 4/11 : RUN pip install --upgrade pip\n",
      " ---> Using cache\n",
      " ---> ca4f4c9b99c3\n",
      "Step 5/11 : COPY requirements.txt requirements.txt\n",
      " ---> Using cache\n",
      " ---> 50cf28c845d7\n",
      "Step 6/11 : RUN pip install -r requirements.txt\n",
      " ---> Using cache\n",
      " ---> 3c9723108cfd\n",
      "Step 7/11 : ENV PATH=\"/opt/ml/code:${PATH}\"\n",
      " ---> Using cache\n",
      " ---> 08ac6cd8073a\n",
      "Step 8/11 : COPY /src /opt/ml/code\n",
      " ---> Using cache\n",
      " ---> 49a335700f62\n",
      "Step 9/11 : RUN chmod -R 755 /opt/ml/code\n",
      " ---> Using cache\n",
      " ---> 8324db4b949d\n",
      "Step 10/11 : ENV SAGEMAKER_SUBMIT_DIRECTORY /opt/ml/code\n",
      " ---> Using cache\n",
      " ---> d97e7939811e\n",
      "Step 11/11 : ENV SAGEMAKER_PROGRAM models/train_da_rnn_model.py\n",
      " ---> Running in 5736f7fd4e9b\n",
      "Removing intermediate container 5736f7fd4e9b\n",
      " ---> 236ce9ac8d23\n",
      "Successfully built 236ce9ac8d23\n",
      "Successfully tagged rl-portfolio-optimization:latest\n",
      "Building RL portfolio optimization image\n",
      "The push refers to repository [662572584943.dkr.ecr.us-east-1.amazonaws.com/rl-portfolio-optimization]\n",
      "\n",
      "\u001b[1B48d1997b: Preparing \n",
      "\u001b[1B64868f5b: Preparing \n",
      "\u001b[1Ba04d734c: Preparing \n",
      "\u001b[1B17763a98: Preparing \n",
      "\u001b[1B9c9ca374: Preparing \n",
      "\u001b[1Bfee2fc55: Preparing \n",
      "\u001b[1Bd9f58f0d: Preparing \n",
      "\u001b[1B2bb41412: Preparing \n",
      "\u001b[1Be204a2b3: Preparing \n",
      "\u001b[1B1bea4fdb: Preparing \n",
      "\u001b[1B4ad3a77b: Preparing \n",
      "\u001b[1Bf2da6055: Preparing \n",
      "\u001b[1Bd9989912: Preparing \n",
      "\u001b[1Bb287a4a5: Preparing \n",
      "\u001b[1B88dd4578: Preparing \n",
      "\u001b[1Bfa438a5e: Preparing \n",
      "\u001b[1B6b51c19f: Preparing \n",
      "\u001b[1Bce785921: Preparing \n",
      "\u001b[1B3ea87e70: Preparing \n",
      "\u001b[1B0266f834: Layer already exists \u001b[15A\u001b[2K\u001b[10A\u001b[2K\u001b[5A\u001b[2Klatest: digest: sha256:9552c09b9eba9473daeb096d9c3fb1948437b9a29d9945dad2e979032000ec93 size: 4523\n"
     ]
    }
   ],
   "source": [
    "!./build_and_push_sagemaker.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing your algorithm on your local machine\n",
    "\n",
    "When you're packaging your first algorithm to use with Amazon SageMaker, you probably want to test it yourself to make sure it's working correctly. We use the [SageMaker Python SDK](https://github.com/aws/sagemaker-python-sdk) to test both locally and on SageMaker. For more examples with the SageMaker Python SDK, see [Amazon SageMaker Examples](https://github.com/awslabs/amazon-sagemaker-examples/tree/master/sagemaker-python-sdk). In order to test our algorithm, we need our dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SageMaker Python SDK Local Training\n",
    "To represent our training, we use the Estimator class, which needs to be configured in five steps. \n",
    "1. IAM role - our AWS execution role\n",
    "2. train_instance_count - number of instances to use for training.\n",
    "3. train_instance_type - type of instance to use for training. For training locally, we specify `local`.\n",
    "4. image_name - our custom PyTorch Docker image we created.\n",
    "5. hyperparameters - hyperparameters we want to pass.\n",
    "\n",
    "Let's start with setting up our IAM role. We make use of a helper function within the Python SDK. This function throw an exception if run outside of a SageMaker notebook instance, as it gets metadata from the notebook instance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the Reinforcement Learning Model Locally\n",
    "Note we are only training for 200 iterations, which is too few to see any increase in the average score.  We are a purely checking for mechanical errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating dwkohi7omq-algo-1-3rm0l ... \n",
      "Creating dwkohi7omq-algo-1-3rm0l ... done\n",
      "Attaching to dwkohi7omq-algo-1-3rm0l\n",
      "\u001b[36mdwkohi7omq-algo-1-3rm0l |\u001b[0m 2021-09-26 22:57:36,800 sagemaker-training-toolkit INFO     Imported framework sagemaker_pytorch_container.training\n",
      "\u001b[36mdwkohi7omq-algo-1-3rm0l |\u001b[0m 2021-09-26 22:57:36,802 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36mdwkohi7omq-algo-1-3rm0l |\u001b[0m 2021-09-26 22:57:36,813 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\n",
      "\u001b[36mdwkohi7omq-algo-1-3rm0l |\u001b[0m 2021-09-26 22:57:36,817 sagemaker_pytorch_container.training INFO     Invoking user training script.\n",
      "\u001b[36mdwkohi7omq-algo-1-3rm0l |\u001b[0m 2021-09-26 22:57:36,820 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36mdwkohi7omq-algo-1-3rm0l |\u001b[0m 2021-09-26 22:57:36,834 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36mdwkohi7omq-algo-1-3rm0l |\u001b[0m 2021-09-26 22:57:36,847 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36mdwkohi7omq-algo-1-3rm0l |\u001b[0m 2021-09-26 22:57:36,860 sagemaker-training-toolkit INFO     Invoking user script\n",
      "\u001b[36mdwkohi7omq-algo-1-3rm0l |\u001b[0m \n",
      "\u001b[36mdwkohi7omq-algo-1-3rm0l |\u001b[0m Training Env:\n",
      "\u001b[36mdwkohi7omq-algo-1-3rm0l |\u001b[0m \n",
      "\u001b[36mdwkohi7omq-algo-1-3rm0l |\u001b[0m {\n",
      "\u001b[36mdwkohi7omq-algo-1-3rm0l |\u001b[0m     \"additional_framework_parameters\": {},\n",
      "\u001b[36mdwkohi7omq-algo-1-3rm0l |\u001b[0m     \"channel_input_dirs\": {},\n",
      "\u001b[36mdwkohi7omq-algo-1-3rm0l |\u001b[0m     \"current_host\": \"algo-1-3rm0l\",\n",
      "\u001b[36mdwkohi7omq-algo-1-3rm0l |\u001b[0m     \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "\u001b[36mdwkohi7omq-algo-1-3rm0l |\u001b[0m     \"hosts\": [\n",
      "\u001b[36mdwkohi7omq-algo-1-3rm0l |\u001b[0m         \"algo-1-3rm0l\"\n",
      "\u001b[36mdwkohi7omq-algo-1-3rm0l |\u001b[0m     ],\n",
      "\u001b[36mdwkohi7omq-algo-1-3rm0l |\u001b[0m     \"hyperparameters\": {\n",
      "\u001b[36mdwkohi7omq-algo-1-3rm0l |\u001b[0m         \"epochs\": 1000\n",
      "\u001b[36mdwkohi7omq-algo-1-3rm0l |\u001b[0m     },\n",
      "\u001b[36mdwkohi7omq-algo-1-3rm0l |\u001b[0m     \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "\u001b[36mdwkohi7omq-algo-1-3rm0l |\u001b[0m     \"input_data_config\": {},\n",
      "\u001b[36mdwkohi7omq-algo-1-3rm0l |\u001b[0m     \"input_dir\": \"/opt/ml/input\",\n",
      "\u001b[36mdwkohi7omq-algo-1-3rm0l |\u001b[0m     \"is_master\": true,\n",
      "\u001b[36mdwkohi7omq-algo-1-3rm0l |\u001b[0m     \"job_name\": \"rl-portfolio-optimization-2021-09-26-22-57-34-374\",\n",
      "\u001b[36mdwkohi7omq-algo-1-3rm0l |\u001b[0m     \"log_level\": 20,\n",
      "\u001b[36mdwkohi7omq-algo-1-3rm0l |\u001b[0m     \"master_hostname\": \"algo-1-3rm0l\",\n",
      "\u001b[36mdwkohi7omq-algo-1-3rm0l |\u001b[0m     \"model_dir\": \"/opt/ml/model\",\n",
      "\u001b[36mdwkohi7omq-algo-1-3rm0l |\u001b[0m     \"module_dir\": \"/opt/ml/code\",\n",
      "\u001b[36mdwkohi7omq-algo-1-3rm0l |\u001b[0m     \"module_name\": \"models/train_da_rnn_model\",\n",
      "\u001b[36mdwkohi7omq-algo-1-3rm0l |\u001b[0m     \"network_interface_name\": \"eth0\",\n",
      "\u001b[36mdwkohi7omq-algo-1-3rm0l |\u001b[0m     \"num_cpus\": 2,\n",
      "\u001b[36mdwkohi7omq-algo-1-3rm0l |\u001b[0m     \"num_gpus\": 0,\n",
      "\u001b[36mdwkohi7omq-algo-1-3rm0l |\u001b[0m     \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "\u001b[36mdwkohi7omq-algo-1-3rm0l |\u001b[0m     \"output_dir\": \"/opt/ml/output\",\n",
      "\u001b[36mdwkohi7omq-algo-1-3rm0l |\u001b[0m     \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "\u001b[36mdwkohi7omq-algo-1-3rm0l |\u001b[0m     \"resource_config\": {\n",
      "\u001b[36mdwkohi7omq-algo-1-3rm0l |\u001b[0m         \"current_host\": \"algo-1-3rm0l\",\n",
      "\u001b[36mdwkohi7omq-algo-1-3rm0l |\u001b[0m         \"hosts\": [\n",
      "\u001b[36mdwkohi7omq-algo-1-3rm0l |\u001b[0m             \"algo-1-3rm0l\"\n",
      "\u001b[36mdwkohi7omq-algo-1-3rm0l |\u001b[0m         ]\n",
      "\u001b[36mdwkohi7omq-algo-1-3rm0l |\u001b[0m     },\n",
      "\u001b[36mdwkohi7omq-algo-1-3rm0l |\u001b[0m     \"user_entry_point\": \"models/train_da_rnn_model.py\"\n",
      "\u001b[36mdwkohi7omq-algo-1-3rm0l |\u001b[0m }\n",
      "\u001b[36mdwkohi7omq-algo-1-3rm0l |\u001b[0m \n",
      "\u001b[36mdwkohi7omq-algo-1-3rm0l |\u001b[0m Environment variables:\n",
      "\u001b[36mdwkohi7omq-algo-1-3rm0l |\u001b[0m \n",
      "\u001b[36mdwkohi7omq-algo-1-3rm0l |\u001b[0m SM_HOSTS=[\"algo-1-3rm0l\"]\n",
      "\u001b[36mdwkohi7omq-algo-1-3rm0l |\u001b[0m SM_NETWORK_INTERFACE_NAME=eth0\n",
      "\u001b[36mdwkohi7omq-algo-1-3rm0l |\u001b[0m SM_HPS={\"epochs\":1000}\n",
      "\u001b[36mdwkohi7omq-algo-1-3rm0l |\u001b[0m SM_USER_ENTRY_POINT=models/train_da_rnn_model.py\n",
      "\u001b[36mdwkohi7omq-algo-1-3rm0l |\u001b[0m SM_FRAMEWORK_PARAMS={}\n",
      "\u001b[36mdwkohi7omq-algo-1-3rm0l |\u001b[0m SM_RESOURCE_CONFIG={\"current_host\":\"algo-1-3rm0l\",\"hosts\":[\"algo-1-3rm0l\"]}\n",
      "\u001b[36mdwkohi7omq-algo-1-3rm0l |\u001b[0m SM_INPUT_DATA_CONFIG={}\n",
      "\u001b[36mdwkohi7omq-algo-1-3rm0l |\u001b[0m SM_OUTPUT_DATA_DIR=/opt/ml/output/data\n",
      "\u001b[36mdwkohi7omq-algo-1-3rm0l |\u001b[0m SM_CHANNELS=[]\n",
      "\u001b[36mdwkohi7omq-algo-1-3rm0l |\u001b[0m SM_CURRENT_HOST=algo-1-3rm0l\n",
      "\u001b[36mdwkohi7omq-algo-1-3rm0l |\u001b[0m SM_MODULE_NAME=models/train_da_rnn_model\n",
      "\u001b[36mdwkohi7omq-algo-1-3rm0l |\u001b[0m SM_LOG_LEVEL=20\n",
      "\u001b[36mdwkohi7omq-algo-1-3rm0l |\u001b[0m SM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\n",
      "\u001b[36mdwkohi7omq-algo-1-3rm0l |\u001b[0m SM_INPUT_DIR=/opt/ml/input\n",
      "\u001b[36mdwkohi7omq-algo-1-3rm0l |\u001b[0m SM_INPUT_CONFIG_DIR=/opt/ml/input/config\n",
      "\u001b[36mdwkohi7omq-algo-1-3rm0l |\u001b[0m SM_OUTPUT_DIR=/opt/ml/output\n",
      "\u001b[36mdwkohi7omq-algo-1-3rm0l |\u001b[0m SM_NUM_CPUS=2\n",
      "\u001b[36mdwkohi7omq-algo-1-3rm0l |\u001b[0m SM_NUM_GPUS=0\n",
      "\u001b[36mdwkohi7omq-algo-1-3rm0l |\u001b[0m SM_MODEL_DIR=/opt/ml/model\n",
      "\u001b[36mdwkohi7omq-algo-1-3rm0l |\u001b[0m SM_MODULE_DIR=/opt/ml/code\n",
      "\u001b[36mdwkohi7omq-algo-1-3rm0l |\u001b[0m SM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{},\"current_host\":\"algo-1-3rm0l\",\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1-3rm0l\"],\"hyperparameters\":{\"epochs\":1000},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"rl-portfolio-optimization-2021-09-26-22-57-34-374\",\"log_level\":20,\"master_hostname\":\"algo-1-3rm0l\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"/opt/ml/code\",\"module_name\":\"models/train_da_rnn_model\",\"network_interface_name\":\"eth0\",\"num_cpus\":2,\"num_gpus\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1-3rm0l\",\"hosts\":[\"algo-1-3rm0l\"]},\"user_entry_point\":\"models/train_da_rnn_model.py\"}\n",
      "\u001b[36mdwkohi7omq-algo-1-3rm0l |\u001b[0m SM_USER_ARGS=[\"--epochs\",\"1000\"]\n",
      "\u001b[36mdwkohi7omq-algo-1-3rm0l |\u001b[0m SM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\n",
      "\u001b[36mdwkohi7omq-algo-1-3rm0l |\u001b[0m SM_HP_EPOCHS=1000\n",
      "\u001b[36mdwkohi7omq-algo-1-3rm0l |\u001b[0m PYTHONPATH=/opt/ml/code:/opt/conda/bin:/opt/conda/lib/python36.zip:/opt/conda/lib/python3.6:/opt/conda/lib/python3.6/lib-dynload:/opt/conda/lib/python3.6/site-packages\n",
      "\u001b[36mdwkohi7omq-algo-1-3rm0l |\u001b[0m \n",
      "\u001b[36mdwkohi7omq-algo-1-3rm0l |\u001b[0m Invoking script with the following command:\n",
      "\u001b[36mdwkohi7omq-algo-1-3rm0l |\u001b[0m \n",
      "\u001b[36mdwkohi7omq-algo-1-3rm0l |\u001b[0m /opt/conda/bin/python3.6 models/train_da_rnn_model.py --epochs 1000\n",
      "\u001b[36mdwkohi7omq-algo-1-3rm0l |\u001b[0m \n",
      "\u001b[36mdwkohi7omq-algo-1-3rm0l |\u001b[0m \n",
      "\u001b[36mdwkohi7omq-algo-1-3rm0l |\u001b[0m Running model training.\n",
      "\u001b[36mdwkohi7omq-algo-1-3rm0l |\u001b[0m Model parameters: Namespace(batch_size=10, decoder_num_hidden=3, encoder_num_hidden=3, epochs=1000, learning_rate=0.5, parallel=False)\n",
      "\u001b[36mdwkohi7omq-algo-1-3rm0l |\u001b[0m ==> Use accelerator:  cpu\n",
      "\u001b[36mdwkohi7omq-algo-1-3rm0l |\u001b[0m -230999.97 training objective.\n",
      "\u001b[36mdwkohi7omq-algo-1-3rm0l |\u001b[0m Done.\n",
      "\u001b[36mdwkohi7omq-algo-1-3rm0l |\u001b[0m \n",
      "\u001b[36mdwkohi7omq-algo-1-3rm0l |\u001b[0m 2021-09-26 22:57:39,613 sagemaker-training-toolkit INFO     Reporting training SUCCESS\n",
      "\u001b[36mdwkohi7omq-algo-1-3rm0l exited with code 0\n",
      "\u001b[0mAborting on container exit...\n",
      "===== Job Complete =====\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.estimator import Estimator\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "role = get_execution_role()\n",
    "estimator = Estimator(role=role,\n",
    "                      instance_count=1,\n",
    "                      instance_type='local',\n",
    "                      image_uri='rl-portfolio-optimization:latest',\n",
    "                      hyperparameters={'epochs': 1000})\n",
    "\n",
    "estimator.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training on SageMaker\n",
    "Training a model on SageMaker with the Python SDK is done in a way that is similar to the way we trained it locally. This is done by changing our train_instance_type from `local` to one of the [supported EC2 instance types](https://aws.amazon.com/sagemaker/pricing/instance-types/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Locate the ECR image just built and pushed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "662572584943.dkr.ecr.us-east-1.amazonaws.com/rl-portfolio-optimization:latest\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "\n",
    "client = boto3.client('sts')\n",
    "account = client.get_caller_identity()['Account']\n",
    "region = boto3.Session().region_name\n",
    "ecr_image = '{}.dkr.ecr.{}.amazonaws.com/rl-portfolio-optimization:latest'.format(account, region)\n",
    "\n",
    "print(ecr_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submit the training job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-09-26 23:23:50 Starting - Starting the training job...\n",
      "2021-09-26 23:23:54 Starting - Launching requested ML instancesProfilerReport-1632698630: InProgress\n",
      ".........\n",
      "2021-09-26 23:25:41 Starting - Preparing the instances for training......\n",
      "2021-09-26 23:26:48 Downloading - Downloading input data\n",
      "2021-09-26 23:26:48 Training - Downloading the training image..............\u001b[34mbash: cannot set terminal process group (-1): Inappropriate ioctl for device\u001b[0m\n",
      "\u001b[34mbash: no job control in this shell\u001b[0m\n",
      "\u001b[34m2021-09-26 23:29:06,887 sagemaker-training-toolkit INFO     Imported framework sagemaker_pytorch_container.training\u001b[0m\n",
      "\u001b[34m2021-09-26 23:29:06,889 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2021-09-26 23:29:06,900 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\u001b[0m\n",
      "\u001b[34m2021-09-26 23:29:06,909 sagemaker_pytorch_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[34m2021-09-26 23:29:06,911 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2021-09-26 23:29:06,925 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2021-09-26 23:29:06,939 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2021-09-26 23:29:06,951 sagemaker-training-toolkit INFO     Invoking user script\n",
      "\u001b[0m\n",
      "\u001b[34mTraining Env:\n",
      "\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {},\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"epochs\": 200\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {},\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"is_master\": true,\n",
      "    \"job_name\": \"rl-portfolio-optimization-2021-09-26-23-23-50-276\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"/opt/ml/code\",\n",
      "    \"module_name\": \"models/train_da_rnn_model\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 4,\n",
      "    \"num_gpus\": 0,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"models/train_da_rnn_model.py\"\u001b[0m\n",
      "\u001b[34m}\n",
      "\u001b[0m\n",
      "\u001b[34mEnvironment variables:\n",
      "\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"epochs\":200}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=models/train_da_rnn_model.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=models/train_da_rnn_model\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=4\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=0\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=/opt/ml/code\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"epochs\":200},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"rl-portfolio-optimization-2021-09-26-23-23-50-276\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"/opt/ml/code\",\"module_name\":\"models/train_da_rnn_model\",\"network_interface_name\":\"eth0\",\"num_cpus\":4,\"num_gpus\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"models/train_da_rnn_model.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--epochs\",\"200\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_HP_EPOCHS=200\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/opt/conda/bin:/opt/conda/lib/python36.zip:/opt/conda/lib/python3.6:/opt/conda/lib/python3.6/lib-dynload:/opt/conda/lib/python3.6/site-packages\n",
      "\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\n",
      "\u001b[0m\n",
      "\u001b[34m/opt/conda/bin/python3.6 models/train_da_rnn_model.py --epochs 200\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[34mRunning model training.\u001b[0m\n",
      "\u001b[34mModel parameters: Namespace(batch_size=10, decoder_num_hidden=3, encoder_num_hidden=3, epochs=200, learning_rate=0.5, parallel=False)\u001b[0m\n",
      "\u001b[34m==> Use accelerator:  cpu\u001b[0m\n",
      "\u001b[34m-230999.66 training objective.\u001b[0m\n",
      "\u001b[34mDone.\n",
      "\u001b[0m\n",
      "\u001b[34m2021-09-26 23:29:09,720 sagemaker-training-toolkit INFO     Reporting training SUCCESS\u001b[0m\n",
      "\n",
      "2021-09-26 23:29:22 Uploading - Uploading generated training model\n",
      "2021-09-26 23:29:22 Completed - Training job completed\n",
      "ProfilerReport-1632698630: NoIssuesFound\n",
      "Training seconds: 152\n",
      "Billable seconds: 152\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.estimator import Estimator\n",
    "estimator = Estimator(role=role,\n",
    "                      instance_count=1,\n",
    "                      instance_type='ml.m4.xlarge',\n",
    "                      image_name=ecr_image,\n",
    "                      image_uri=ecr_image,\n",
    "                      hyperparameters={'epochs': 200})\n",
    "estimator.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p36",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

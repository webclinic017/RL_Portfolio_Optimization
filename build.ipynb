{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building and registering the container\n",
    "\n",
    "The `build-and-push.sh` builds the container image using `docker build` and push the container image to ECR using `docker push`. \n",
    "\n",
    "If the `gpu` argument is passed to `build-and-push.sh` the GPU Docker file is used to create the GPU instance.  Otherwise the CPU instance is created.\n",
    "\n",
    "This code looks for an ECR repository in the account you're using and the current default region (if you're using a SageMaker notebook instance, this is the region where the notebook instance was created). If the repository doesn't exist, the script will create it. In addition, since we are using the SageMaker PyTorch image as the base, we will need to retrieve ECR credentials to pull this public image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requesting CPU image\n",
      "Login Succeeded\n",
      "Login Succeeded\n",
      "Sending build context to Docker daemon  178.8MB\n",
      "Step 1/10 : ARG REGION=us-east-1\n",
      "Step 2/10 : FROM 520713654638.dkr.ecr.$REGION.amazonaws.com/sagemaker-pytorch:1.1.0-cpu-py3\n",
      "1.1.0-cpu-py3: Pulling from sagemaker-pytorch\n",
      "\n",
      "\u001b[1B7927d38a: Pulling fs layer \n",
      "\u001b[1Bac894db4: Pulling fs layer \n",
      "\u001b[1B2af6d627: Pulling fs layer \n",
      "\u001b[1B86211d23: Pulling fs layer \n",
      "\u001b[1Baf39bebe: Pulling fs layer \n",
      "\u001b[1B03f425cd: Pulling fs layer \n",
      "\u001b[1B1ec18efe: Pulling fs layer \n",
      "\u001b[1B8ad8ba55: Pulling fs layer \n",
      "\u001b[1B6c282ffb: Pulling fs layer \n",
      "\u001b[1B77dfb459: Pulling fs layer \n",
      "\u001b[1Bbbd8c730: Pulling fs layer \n",
      "\u001b[1BDigest: sha256:bd973d810e8cf494a37dc9cc477b619d13da901d5f2804a953064b5bafc1e484[1K\u001b[K\u001b[8A\u001b[1K\u001b[K\u001b[7A\u001b[1K\u001b[K\u001b[8A\u001b[1K\u001b[K\u001b[8A\u001b[1K\u001b[K\u001b[6A\u001b[1K\u001b[K\u001b[8A\u001b[1K\u001b[K\u001b[6A\u001b[1K\u001b[K\u001b[8A\u001b[1K\u001b[K\u001b[6A\u001b[1K\u001b[K\u001b[8A\u001b[1K\u001b[K\u001b[6A\u001b[1K\u001b[K\u001b[8A\u001b[1K\u001b[K\u001b[6A\u001b[1K\u001b[K\u001b[8A\u001b[1K\u001b[K\u001b[12A\u001b[1K\u001b[K\u001b[8A\u001b[1K\u001b[K\u001b[12A\u001b[1K\u001b[K\u001b[8A\u001b[1K\u001b[K\u001b[12A\u001b[1K\u001b[K\u001b[8A\u001b[1K\u001b[K\u001b[5A\u001b[1K\u001b[K\u001b[4A\u001b[1K\u001b[K\u001b[8A\u001b[1K\u001b[K\u001b[3A\u001b[1K\u001b[K\u001b[12A\u001b[1K\u001b[K\u001b[8A\u001b[1K\u001b[K\u001b[12A\u001b[1K\u001b[K\u001b[8A\u001b[1K\u001b[K\u001b[12A\u001b[1K\u001b[K\u001b[8A\u001b[1K\u001b[K\u001b[8A\u001b[1K\u001b[K\u001b[1A\u001b[1K\u001b[K\u001b[6A\u001b[1K\u001b[K\u001b[12A\u001b[1K\u001b[K\u001b[6A\u001b[1K\u001b[K\u001b[8A\u001b[1K\u001b[K\u001b[6A\u001b[1K\u001b[K\u001b[12A\u001b[1K\u001b[K\u001b[6A\u001b[1K\u001b[K\u001b[1A\u001b[1K\u001b[K\u001b[6A\u001b[1K\u001b[K\u001b[1A\u001b[1K\u001b[K\u001b[12A\u001b[1K\u001b[K\u001b[1A\u001b[1K\u001b[K\u001b[12A\u001b[1K\u001b[K\u001b[1A\u001b[1K\u001b[K\u001b[6A\u001b[1K\u001b[K\u001b[1A\u001b[1K\u001b[K\u001b[6A\u001b[1K\u001b[K\u001b[1A\u001b[1K\u001b[K\u001b[12A\u001b[1K\u001b[K\u001b[1A\u001b[1K\u001b[K\u001b[12A\u001b[1K\u001b[K\u001b[12A\u001b[1K\u001b[K\u001b[12A\u001b[1K\u001b[K\u001b[6A\u001b[1K\u001b[K\u001b[12A\u001b[1K\u001b[K\u001b[6A\u001b[1K\u001b[K\u001b[12A\u001b[1K\u001b[K\u001b[6A\u001b[1K\u001b[K\u001b[12A\u001b[1K\u001b[K\u001b[6A\u001b[1K\u001b[K\u001b[12A\u001b[1K\u001b[K\u001b[6A\u001b[1K\u001b[K\u001b[6A\u001b[1K\u001b[K\u001b[6A\u001b[1K\u001b[K\u001b[6A\u001b[1K\u001b[K\u001b[6A\u001b[1K\u001b[K\u001b[6A\u001b[1K\u001b[K\u001b[6A\u001b[1K\u001b[K\u001b[6A\u001b[1K\u001b[K\u001b[6A\u001b[1K\u001b[K\u001b[6A\u001b[1K\u001b[K\u001b[6A\u001b[1K\u001b[K\u001b[6A\u001b[1K\u001b[K\u001b[6A\u001b[1K\u001b[K\u001b[6A\u001b[1K\u001b[K\u001b[6A\u001b[1K\u001b[K\u001b[6A\u001b[1K\u001b[K\u001b[6A\u001b[1K\u001b[K\u001b[11A\u001b[1K\u001b[K\u001b[11A\u001b[1K\u001b[K\u001b[10A\u001b[1K\u001b[K\u001b[10A\u001b[1K\u001b[K\u001b[9A\u001b[1K\u001b[K\u001b[8A\u001b[1K\u001b[K\u001b[8A\u001b[1K\u001b[K\u001b[8A\u001b[1K\u001b[K\u001b[8A\u001b[1K\u001b[K\u001b[8A\u001b[1K\u001b[K\u001b[8A\u001b[1K\u001b[K\u001b[8A\u001b[1K\u001b[K\u001b[8A\u001b[1K\u001b[K\u001b[8A\u001b[1K\u001b[K\u001b[8A\u001b[1K\u001b[K\u001b[8A\u001b[1K\u001b[K\u001b[8A\u001b[1K\u001b[K\u001b[8A\u001b[1K\u001b[K\u001b[8A\u001b[1K\u001b[K\u001b[8A\u001b[1K\u001b[K\u001b[8A\u001b[1K\u001b[K\u001b[8A\u001b[1K\u001b[K\u001b[8A\u001b[1K\u001b[K\u001b[8A\u001b[1K\u001b[K\u001b[8A\u001b[1K\u001b[K\u001b[8A\u001b[1K\u001b[K\u001b[8A\u001b[1K\u001b[K\u001b[8A\u001b[1K\u001b[K\u001b[8A\u001b[1K\u001b[K\u001b[8A\u001b[1K\u001b[K\u001b[8A\u001b[1K\u001b[K\u001b[8A\u001b[1K\u001b[K\u001b[8A\u001b[1K\u001b[K\u001b[8A\u001b[1K\u001b[K\u001b[8A\u001b[1K\u001b[K\u001b[8A\u001b[1K\u001b[K\u001b[8A\u001b[1K\u001b[K\u001b[8A\u001b[1K\u001b[K\u001b[8A\u001b[1K\u001b[K\u001b[8A\u001b[1K\u001b[K\u001b[8A\u001b[1K\u001b[K\u001b[8A\u001b[1K\u001b[K\u001b[7A\u001b[1K\u001b[K\u001b[7A\u001b[1K\u001b[K\u001b[7A\u001b[1K\u001b[K\u001b[7A\u001b[1K\u001b[K\u001b[6A\u001b[1K\u001b[K\u001b[6A\u001b[1K\u001b[K\u001b[6A\u001b[1K\u001b[K\u001b[6A\u001b[1K\u001b[K\u001b[6A\u001b[1K\u001b[K\u001b[6A\u001b[1K\u001b[K\u001b[6A\u001b[1K\u001b[K\u001b[6A\u001b[1K\u001b[K\u001b[6A\u001b[1K\u001b[K\u001b[6A\u001b[1K\u001b[K\u001b[6A\u001b[1K\u001b[K\u001b[6A\u001b[1K\u001b[K\u001b[6A\u001b[1K\u001b[K\u001b[6A\u001b[1K\u001b[K\u001b[6A\u001b[1K\u001b[K\u001b[6A\u001b[1K\u001b[K\u001b[6A\u001b[1K\u001b[K\u001b[6A\u001b[1K\u001b[K\u001b[6A\u001b[1K\u001b[K\u001b[6A\u001b[1K\u001b[K\u001b[6A\u001b[1K\u001b[K\u001b[6A\u001b[1K\u001b[K\u001b[6A\u001b[1K\u001b[K\u001b[6A\u001b[1K\u001b[K\u001b[6A\u001b[1K\u001b[K\u001b[6A\u001b[1K\u001b[K\u001b[6A\u001b[1K\u001b[K\u001b[6A\u001b[1K\u001b[K\u001b[6A\u001b[1K\u001b[K\u001b[6A\u001b[1K\u001b[K\u001b[6A\u001b[1K\u001b[K\u001b[6A\u001b[1K\u001b[K\u001b[6A\u001b[1K\u001b[K\u001b[6A\u001b[1K\u001b[K\u001b[6A\u001b[1K\u001b[K\u001b[6A\u001b[1K\u001b[K\u001b[6A\u001b[1K\u001b[K\u001b[6A\u001b[1K\u001b[K\u001b[6A\u001b[1K\u001b[K\u001b[6A\u001b[1K\u001b[K\u001b[6A\u001b[1K\u001b[K\u001b[6A\u001b[1K\u001b[K\u001b[6A\u001b[1K\u001b[K\u001b[6A\u001b[1K\u001b[K\u001b[6A\u001b[1K\u001b[K\u001b[6A\u001b[1K\u001b[K\u001b[6A\u001b[1K\u001b[K\u001b[6A\u001b[1K\u001b[K\u001b[6A\u001b[1K\u001b[K\u001b[6A\u001b[1K\u001b[K\u001b[6A\u001b[1K\u001b[K\u001b[6A\u001b[1K\u001b[K\u001b[6A\u001b[1K\u001b[K\u001b[6A\u001b[1K\u001b[K\u001b[6A\u001b[1K\u001b[K\u001b[6A\u001b[1K\u001b[K\u001b[6A\u001b[1K\u001b[K\u001b[6A\u001b[1K\u001b[K\u001b[6A\u001b[1K\u001b[K\u001b[6A\u001b[1K\u001b[K\u001b[6A\u001b[1K\u001b[K\u001b[6A\u001b[1K\u001b[K\u001b[6A\u001b[1K\u001b[K\u001b[6A\u001b[1K\u001b[K\u001b[6A\u001b[1K\u001b[K\u001b[6A\u001b[1K\u001b[K\u001b[6A\u001b[1K\u001b[K\u001b[6A\u001b[1K\u001b[K\u001b[6A\u001b[1K\u001b[K\u001b[6A\u001b[1K\u001b[K\u001b[6A\u001b[1K\u001b[K\u001b[6A\u001b[1K\u001b[K\u001b[6A\u001b[1K\u001b[K\u001b[6A\u001b[1K\u001b[K\u001b[6A\u001b[1K\u001b[K\u001b[6A\u001b[1K\u001b[K\u001b[6A\u001b[1K\u001b[K\u001b[6A\u001b[1K\u001b[K\u001b[6A\u001b[1K\u001b[K\u001b[6A\u001b[1K\u001b[K\u001b[6A\u001b[1K\u001b[K\u001b[6A\u001b[1K\u001b[K\u001b[6A\u001b[1K\u001b[K\u001b[6A\u001b[1K\u001b[K\u001b[6A\u001b[1K\u001b[K\u001b[6A\u001b[1K\u001b[K\u001b[6A\u001b[1K\u001b[K\u001b[6A\u001b[1K\u001b[K\u001b[6A\u001b[1K\u001b[K\u001b[6A\u001b[1K\u001b[K\u001b[6A\u001b[1K\u001b[K\u001b[6A\u001b[1K\u001b[K\u001b[6A\u001b[1K\u001b[K\u001b[6A\u001b[1K\u001b[K\u001b[5A\u001b[1K\u001b[K\u001b[5A\u001b[1K\u001b[K\u001b[4A\u001b[1K\u001b[K\u001b[4A\u001b[1K\u001b[K\u001b[3A\u001b[1K\u001b[K\u001b[2A\u001b[1K\u001b[K\u001b[2A\u001b[1K\u001b[K\u001b[1A\u001b[1K\u001b[K\u001b[1A\u001b[1K\u001b[K\u001b[1A\u001b[1K\u001b[K\u001b[1A\u001b[1K\u001b[K\u001b[1A\u001b[1K\u001b[K\u001b[1A\u001b[1K\u001b[K\u001b[1A\u001b[1K\u001b[K\u001b[1A\u001b[1K\u001b[K\u001b[1A\u001b[1K\u001b[K\u001b[1A\u001b[1K\u001b[K\u001b[1A\u001b[1K\u001b[K\u001b[1A\u001b[1K\u001b[K\u001b[1A\u001b[1K\u001b[K\u001b[1A\u001b[1K\u001b[K\u001b[1A\u001b[1K\u001b[K\u001b[1A\u001b[1K\u001b[K\u001b[1A\u001b[1K\u001b[K\u001b[1A\u001b[1K\u001b[K\u001b[1A\u001b[1K\u001b[K\n",
      "Status: Downloaded newer image for 520713654638.dkr.ecr.us-east-1.amazonaws.com/sagemaker-pytorch:1.1.0-cpu-py3\n",
      " ---> d374fb352c72\n",
      "Step 3/10 : RUN pip install --upgrade pip\n",
      " ---> Running in ac5ba6f64b73\n",
      "Collecting pip\n",
      "  Downloading https://files.pythonhosted.org/packages/43/84/23ed6a1796480a6f1a2d38f2802901d078266bda38388954d01d3f2e821d/pip-20.1.1-py2.py3-none-any.whl (1.5MB)\n",
      "Installing collected packages: pip\n",
      "  Found existing installation: pip 18.1\n",
      "    Uninstalling pip-18.1:\n",
      "      Successfully uninstalled pip-18.1\n",
      "Successfully installed pip-20.1.1\n",
      "Removing intermediate container ac5ba6f64b73\n",
      " ---> d65915466bcd\n",
      "Step 4/10 : COPY requirements.txt requirements.txt\n",
      " ---> 076291856580\n",
      "Step 5/10 : RUN pip install -r requirements.txt\n",
      " ---> Running in e29ef68688d1\n",
      "Collecting grpcio-tools\n",
      "  Downloading grpcio_tools-1.30.0-cp36-cp36m-manylinux2010_x86_64.whl (2.5 MB)\n",
      "Collecting gym\n",
      "  Downloading gym-0.17.2.tar.gz (1.6 MB)\n",
      "Collecting box2d-py~=2.3.5\n",
      "  Downloading box2d_py-2.3.8-cp36-cp36m-manylinux1_x86_64.whl (448 kB)\n",
      "Collecting protobuf>=3.5.0.post1\n",
      "  Downloading protobuf-3.12.2-cp36-cp36m-manylinux1_x86_64.whl (1.3 MB)\n",
      "Collecting grpcio>=1.30.0\n",
      "  Downloading grpcio-1.30.0-cp36-cp36m-manylinux2010_x86_64.whl (3.0 MB)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from gym->-r requirements.txt (line 2)) (1.3.1)\n",
      "Requirement already satisfied: numpy>=1.10.4 in /usr/local/lib/python3.6/dist-packages (from gym->-r requirements.txt (line 2)) (1.16.4)\n",
      "Collecting pyglet<=1.5.0,>=1.4.0\n",
      "  Downloading pyglet-1.5.0-py2.py3-none-any.whl (1.0 MB)\n",
      "Collecting cloudpickle<1.4.0,>=1.2.0\n",
      "  Downloading cloudpickle-1.3.0-py2.py3-none-any.whl (26 kB)\n",
      "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.5.0.post1->grpcio-tools->-r requirements.txt (line 1)) (1.12.0)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.5.0.post1->grpcio-tools->-r requirements.txt (line 1)) (41.1.0)\n",
      "Collecting future\n",
      "  Downloading future-0.18.2.tar.gz (829 kB)\n",
      "Building wheels for collected packages: gym, future\n",
      "  Building wheel for gym (setup.py): started\n",
      "  Building wheel for gym (setup.py): finished with status 'done'\n",
      "  Created wheel for gym: filename=gym-0.17.2-py3-none-any.whl size=1650891 sha256=1ea88fbbd3f9682e37a33c5ff2c9e96a8f2a4638e6912985e0b953e3ad42ee32\n",
      "  Stored in directory: /root/.cache/pip/wheels/be/a1/84/6b4caa6c1cea703acbfea8a24cc3c1729bd359cd4a65755d8b\n",
      "  Building wheel for future (setup.py): started\n",
      "  Building wheel for future (setup.py): finished with status 'done'\n",
      "  Created wheel for future: filename=future-0.18.2-py3-none-any.whl size=491058 sha256=32f9d168e6ce425960b0bf60b1d2dfbc29ab05d36133b64d81af438f99434b64\n",
      "  Stored in directory: /root/.cache/pip/wheels/6e/9c/ed/4499c9865ac1002697793e0ae05ba6be33553d098f3347fb94\n",
      "Successfully built gym future\n",
      "Installing collected packages: protobuf, grpcio, grpcio-tools, future, pyglet, cloudpickle, gym, box2d-py\n",
      "Successfully installed box2d-py-2.3.8 cloudpickle-1.3.0 future-0.18.2 grpcio-1.30.0 grpcio-tools-1.30.0 gym-0.17.2 protobuf-3.12.2 pyglet-1.5.0\n",
      "Removing intermediate container e29ef68688d1\n",
      " ---> b6b7d1876658\n",
      "Step 6/10 : ENV PATH=\"/opt/ml/code:${PATH}\"\n",
      " ---> Running in c00a2448e01c\n",
      "Removing intermediate container c00a2448e01c\n",
      " ---> d47d578bdf87\n",
      "Step 7/10 : COPY /src /opt/ml/code\n",
      " ---> 15072931a941\n",
      "Step 8/10 : RUN chmod -R 755 /opt/ml/code\n",
      " ---> Running in b18d8dbecd40\n",
      "Removing intermediate container b18d8dbecd40\n",
      " ---> f04ad4f32e30\n",
      "Step 9/10 : ENV SAGEMAKER_SUBMIT_DIRECTORY /opt/ml/code\n",
      " ---> Running in 5014dabfd09b\n",
      "Removing intermediate container 5014dabfd09b\n",
      " ---> ae9c6b473ebc\n",
      "Step 10/10 : ENV SAGEMAKER_PROGRAM train.py\n",
      " ---> Running in 4a8b7f2ca4fd\n",
      "Removing intermediate container 4a8b7f2ca4fd\n",
      " ---> 9d413381f8ae\n",
      "Successfully built 9d413381f8ae\n",
      "Successfully tagged sagemaker-tennis-cpu:latest\n",
      "Building CPU image\n",
      "The push refers to repository [031118886020.dkr.ecr.us-east-1.amazonaws.com/sagemaker-tennis-cpu]\n",
      "\n",
      "\u001b[1Bb62ef907: Preparing \n",
      "\u001b[1B0fc5303c: Preparing \n",
      "\u001b[1B937dd526: Preparing \n",
      "\u001b[1B650268ac: Preparing \n",
      "\u001b[1B7d608e97: Preparing \n",
      "\u001b[1Becc4e4d4: Preparing \n",
      "\u001b[1B808cebd3: Preparing \n",
      "\u001b[1Bf05eda79: Preparing \n",
      "\u001b[1B71db9add: Preparing \n",
      "\u001b[1B53464ab3: Preparing \n",
      "\u001b[1Bc4bd5031: Preparing \n",
      "\u001b[1Bd01ff144: Preparing \n",
      "\u001b[1B7f77d9db: Preparing \n",
      "\u001b[1B42719515: Preparing \n",
      "\u001b[1B103e78c9: Preparing \n",
      "\u001b[1Be637fbff: Preparing \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[17B62ef907: Pushed   114.7MB/114.5MB\u001b[16A\u001b[1K\u001b[K\u001b[13A\u001b[1K\u001b[K\u001b[16A\u001b[1K\u001b[K\u001b[16A\u001b[1K\u001b[K\u001b[13A\u001b[1K\u001b[K\u001b[15A\u001b[1K\u001b[K\u001b[13A\u001b[1K\u001b[K\u001b[17A\u001b[1K\u001b[K\u001b[17A\u001b[1K\u001b[K\u001b[15A\u001b[1K\u001b[K\u001b[13A\u001b[1K\u001b[K\u001b[15A\u001b[1K\u001b[K\u001b[16A\u001b[1K\u001b[K\u001b[13A\u001b[1K\u001b[K\u001b[17A\u001b[1K\u001b[K\u001b[13A\u001b[1K\u001b[K\u001b[16A\u001b[1K\u001b[K\u001b[13A\u001b[1K\u001b[K\u001b[15A\u001b[1K\u001b[K\u001b[16A\u001b[1K\u001b[K\u001b[17A\u001b[1K\u001b[K\u001b[13A\u001b[1K\u001b[K\u001b[13A\u001b[1K\u001b[K\u001b[16A\u001b[1K\u001b[K\u001b[17A\u001b[1K\u001b[K\u001b[16A\u001b[1K\u001b[K\u001b[16A\u001b[1K\u001b[K\u001b[17A\u001b[1K\u001b[K\u001b[15A\u001b[1K\u001b[K\u001b[16A\u001b[1K\u001b[K\u001b[16A\u001b[1K\u001b[K\u001b[15A\u001b[1K\u001b[K\u001b[16A\u001b[1K\u001b[K\u001b[17A\u001b[1K\u001b[K\u001b[13A\u001b[1K\u001b[K\u001b[15A\u001b[1K\u001b[K\u001b[16A\u001b[1K\u001b[K\u001b[15A\u001b[1K\u001b[K\u001b[17A\u001b[1K\u001b[K\u001b[16A\u001b[1K\u001b[K\u001b[15A\u001b[1K\u001b[K\u001b[13A\u001b[1K\u001b[K\u001b[17A\u001b[1K\u001b[K\u001b[13A\u001b[1K\u001b[K\u001b[17A\u001b[1K\u001b[K\u001b[13A\u001b[1K\u001b[K\u001b[16A\u001b[1K\u001b[K\u001b[13A\u001b[1K\u001b[K\u001b[16A\u001b[1K\u001b[K\u001b[17A\u001b[1K\u001b[K\u001b[16A\u001b[1K\u001b[K\u001b[17A\u001b[1K\u001b[K\u001b[16A\u001b[1K\u001b[K\u001b[13A\u001b[1K\u001b[K\u001b[16A\u001b[1K\u001b[K\u001b[17A\u001b[1K\u001b[K\u001b[15A\u001b[1K\u001b[K\u001b[17A\u001b[1K\u001b[K\u001b[16A\u001b[1K\u001b[K\u001b[17A\u001b[1K\u001b[K\u001b[16A\u001b[1K\u001b[K\u001b[17A\u001b[1K\u001b[K\u001b[16A\u001b[1K\u001b[K\u001b[17A\u001b[1K\u001b[K\u001b[13A\u001b[1K\u001b[K\u001b[17A\u001b[1K\u001b[K\u001b[13A\u001b[1K\u001b[K\u001b[16A\u001b[1K\u001b[K\u001b[13A\u001b[1K\u001b[K\u001b[13A\u001b[1K\u001b[K\u001b[17A\u001b[1K\u001b[K\u001b[17A\u001b[1K\u001b[K\u001b[16A\u001b[1K\u001b[K\u001b[13A\u001b[1K\u001b[K\u001b[16A\u001b[1K\u001b[K\u001b[10A\u001b[1K\u001b[K\u001b[16A\u001b[1K\u001b[K\u001b[13A\u001b[1K\u001b[K\u001b[17A\u001b[1K\u001b[K\u001b[17A\u001b[1K\u001b[K\u001b[16A\u001b[1K\u001b[K\u001b[17A\u001b[1K\u001b[K\u001b[16A\u001b[1K\u001b[K\u001b[17A\u001b[1K\u001b[K\u001b[15A\u001b[1K\u001b[K\u001b[16A\u001b[1K\u001b[K\u001b[16A\u001b[1K\u001b[K\u001b[17A\u001b[1K\u001b[K\u001b[16A\u001b[1K\u001b[K\u001b[17A\u001b[1K\u001b[K\u001b[9A\u001b[1K\u001b[K\u001b[17A\u001b[1K\u001b[K\u001b[15A\u001b[1K\u001b[K\u001b[16A\u001b[1K\u001b[K\u001b[17A\u001b[1K\u001b[K\u001b[15A\u001b[1K\u001b[K\u001b[17A\u001b[1K\u001b[K\u001b[16A\u001b[1K\u001b[K\u001b[17A\u001b[1K\u001b[K\u001b[15A\u001b[1K\u001b[K\u001b[17A\u001b[1K\u001b[K\u001b[16A\u001b[1K\u001b[K\u001b[16A\u001b[1K\u001b[K\u001b[15A\u001b[1K\u001b[K\u001b[16A\u001b[1K\u001b[K\u001b[15A\u001b[1K\u001b[K\u001b[17A\u001b[1K\u001b[K\u001b[8A\u001b[1K\u001b[K\u001b[16A\u001b[1K\u001b[K\u001b[15A\u001b[1K\u001b[K\u001b[16A\u001b[1K\u001b[K\u001b[16A\u001b[1K\u001b[K\u001b[17A\u001b[1K\u001b[K\u001b[16A\u001b[1K\u001b[K\u001b[15A\u001b[1K\u001b[K\u001b[16A\u001b[1K\u001b[K\u001b[17A\u001b[1K\u001b[K\u001b[16A\u001b[1K\u001b[K\u001b[15A\u001b[1K\u001b[K\u001b[16A\u001b[1K\u001b[K\u001b[16A\u001b[1K\u001b[K\u001b[17A\u001b[1K\u001b[K\u001b[16A\u001b[1K\u001b[K\u001b[15A\u001b[1K\u001b[K\u001b[7A\u001b[1K\u001b[K\u001b[15A\u001b[1K\u001b[K\u001b[16A\u001b[1K\u001b[K\u001b[15A\u001b[1K\u001b[K\u001b[5A\u001b[1K\u001b[K\u001b[4A\u001b[1K\u001b[K\u001b[17A\u001b[1K\u001b[K\u001b[17A\u001b[1K\u001b[K\u001b[15A\u001b[1K\u001b[K\u001b[3A\u001b[1K\u001b[K\u001b[17A\u001b[1K\u001b[K\u001b[17A\u001b[1K\u001b[K\u001b[15A\u001b[1K\u001b[K\u001b[17A\u001b[1K\u001b[K\u001b[17A\u001b[1K\u001b[K\u001b[16A\u001b[1K\u001b[K\u001b[17A\u001b[1K\u001b[K\u001b[17A\u001b[1K\u001b[K\u001b[17A\u001b[1K\u001b[K\u001b[15A\u001b[1K\u001b[K\u001b[17A\u001b[1K\u001b[K\u001b[17A\u001b[1K\u001b[Klatest: digest: sha256:92eee7ea22ebb1445a678939ff0bb45942ec1a5d41c827b9685ce81411c039a1 size: 3883\n"
     ]
    }
   ],
   "source": [
    "!./build_and_push_sagemaker.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing your algorithm on your local machine\n",
    "\n",
    "When you're packaging your first algorithm to use with Amazon SageMaker, you probably want to test it yourself to make sure it's working correctly. We use the [SageMaker Python SDK](https://github.com/aws/sagemaker-python-sdk) to test both locally and on SageMaker. For more examples with the SageMaker Python SDK, see [Amazon SageMaker Examples](https://github.com/awslabs/amazon-sagemaker-examples/tree/master/sagemaker-python-sdk). In order to test our algorithm, we need our dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SageMaker Python SDK Local Training\n",
    "To represent our training, we use the Estimator class, which needs to be configured in five steps. \n",
    "1. IAM role - our AWS execution role\n",
    "2. train_instance_count - number of instances to use for training.\n",
    "3. train_instance_type - type of instance to use for training. For training locally, we specify `local`.\n",
    "4. image_name - our custom PyTorch Docker image we created.\n",
    "5. hyperparameters - hyperparameters we want to pass.\n",
    "\n",
    "Let's start with setting up our IAM role. We make use of a helper function within the Python SDK. This function throw an exception if run outside of a SageMaker notebook instance, as it gets metadata from the notebook instance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the Reinforcement Learning Model Locally\n",
    "Note we are only training for 200 iterations, which is too few to see any increase in the average score.  We are a purely checking for mechanical errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating tmpl4u04c4__algo-1-dwbrk_1 ... \n",
      "\u001b[1BAttaching to tmpl4u04c4__algo-1-dwbrk_12mdone\u001b[0m\n",
      "\u001b[36malgo-1-dwbrk_1  |\u001b[0m 2020-07-04 15:34:24,066 sagemaker-containers INFO     Imported framework sagemaker_pytorch_container.training\n",
      "\u001b[36malgo-1-dwbrk_1  |\u001b[0m 2020-07-04 15:34:24,070 sagemaker-containers INFO     No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36malgo-1-dwbrk_1  |\u001b[0m 2020-07-04 15:34:24,084 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\n",
      "\u001b[36malgo-1-dwbrk_1  |\u001b[0m 2020-07-04 15:34:24,088 sagemaker_pytorch_container.training INFO     Invoking user training script.\n",
      "\u001b[36malgo-1-dwbrk_1  |\u001b[0m 2020-07-04 15:34:24,089 sagemaker-containers INFO     Module train does not provide a setup.py. \n",
      "\u001b[36malgo-1-dwbrk_1  |\u001b[0m Generating setup.py\n",
      "\u001b[36malgo-1-dwbrk_1  |\u001b[0m 2020-07-04 15:34:24,090 sagemaker-containers INFO     Generating setup.cfg\n",
      "\u001b[36malgo-1-dwbrk_1  |\u001b[0m 2020-07-04 15:34:24,090 sagemaker-containers INFO     Generating MANIFEST.in\n",
      "\u001b[36malgo-1-dwbrk_1  |\u001b[0m 2020-07-04 15:34:24,090 sagemaker-containers INFO     Installing module with the following command:\n",
      "\u001b[36malgo-1-dwbrk_1  |\u001b[0m /usr/bin/python -m pip install . \n",
      "\u001b[36malgo-1-dwbrk_1  |\u001b[0m Processing /opt/ml/code\n",
      "\u001b[36malgo-1-dwbrk_1  |\u001b[0m Building wheels for collected packages: train\n",
      "\u001b[36malgo-1-dwbrk_1  |\u001b[0m   Building wheel for train (setup.py) ... \u001b[?25ldone\n",
      "\u001b[36malgo-1-dwbrk_1  |\u001b[0m \u001b[?25h  Created wheel for train: filename=train-1.0.0-py2.py3-none-any.whl size=45199378 sha256=bbfe7c8fcd55829e755556f37466ad480efb9e35c89171e44b0f18db5fbc9041\n",
      "\u001b[36malgo-1-dwbrk_1  |\u001b[0m   Stored in directory: /tmp/pip-ephem-wheel-cache-rrvc2ie6/wheels/95/c1/85/65aaf48b35aba88c6e896d2fd04a4b69f1cee0d81ea32993ca\n",
      "\u001b[36malgo-1-dwbrk_1  |\u001b[0m Successfully built train\n",
      "\u001b[36malgo-1-dwbrk_1  |\u001b[0m Installing collected packages: train\n",
      "\u001b[36malgo-1-dwbrk_1  |\u001b[0m Successfully installed train-1.0.0\n",
      "\u001b[36malgo-1-dwbrk_1  |\u001b[0m 2020-07-04 15:34:37,849 sagemaker-containers INFO     No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36malgo-1-dwbrk_1  |\u001b[0m 2020-07-04 15:34:37,863 sagemaker-containers INFO     Invoking user script\n",
      "\u001b[36malgo-1-dwbrk_1  |\u001b[0m \n",
      "\u001b[36malgo-1-dwbrk_1  |\u001b[0m Training Env:\n",
      "\u001b[36malgo-1-dwbrk_1  |\u001b[0m \n",
      "\u001b[36malgo-1-dwbrk_1  |\u001b[0m {\n",
      "\u001b[36malgo-1-dwbrk_1  |\u001b[0m     \"additional_framework_parameters\": {},\n",
      "\u001b[36malgo-1-dwbrk_1  |\u001b[0m     \"channel_input_dirs\": {},\n",
      "\u001b[36malgo-1-dwbrk_1  |\u001b[0m     \"current_host\": \"algo-1-dwbrk\",\n",
      "\u001b[36malgo-1-dwbrk_1  |\u001b[0m     \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "\u001b[36malgo-1-dwbrk_1  |\u001b[0m     \"hosts\": [\n",
      "\u001b[36malgo-1-dwbrk_1  |\u001b[0m         \"algo-1-dwbrk\"\n",
      "\u001b[36malgo-1-dwbrk_1  |\u001b[0m     ],\n",
      "\u001b[36malgo-1-dwbrk_1  |\u001b[0m     \"hyperparameters\": {\n",
      "\u001b[36malgo-1-dwbrk_1  |\u001b[0m         \"epochs\": 200\n",
      "\u001b[36malgo-1-dwbrk_1  |\u001b[0m     },\n",
      "\u001b[36malgo-1-dwbrk_1  |\u001b[0m     \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "\u001b[36malgo-1-dwbrk_1  |\u001b[0m     \"input_data_config\": {},\n",
      "\u001b[36malgo-1-dwbrk_1  |\u001b[0m     \"input_dir\": \"/opt/ml/input\",\n",
      "\u001b[36malgo-1-dwbrk_1  |\u001b[0m     \"is_master\": true,\n",
      "\u001b[36malgo-1-dwbrk_1  |\u001b[0m     \"job_name\": \"sagemaker-tennis-cpu-2020-07-04-15-34-21-570\",\n",
      "\u001b[36malgo-1-dwbrk_1  |\u001b[0m     \"log_level\": 20,\n",
      "\u001b[36malgo-1-dwbrk_1  |\u001b[0m     \"master_hostname\": \"algo-1-dwbrk\",\n",
      "\u001b[36malgo-1-dwbrk_1  |\u001b[0m     \"model_dir\": \"/opt/ml/model\",\n",
      "\u001b[36malgo-1-dwbrk_1  |\u001b[0m     \"module_dir\": \"/opt/ml/code\",\n",
      "\u001b[36malgo-1-dwbrk_1  |\u001b[0m     \"module_name\": \"train\",\n",
      "\u001b[36malgo-1-dwbrk_1  |\u001b[0m     \"network_interface_name\": \"eth0\",\n",
      "\u001b[36malgo-1-dwbrk_1  |\u001b[0m     \"num_cpus\": 2,\n",
      "\u001b[36malgo-1-dwbrk_1  |\u001b[0m     \"num_gpus\": 0,\n",
      "\u001b[36malgo-1-dwbrk_1  |\u001b[0m     \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "\u001b[36malgo-1-dwbrk_1  |\u001b[0m     \"output_dir\": \"/opt/ml/output\",\n",
      "\u001b[36malgo-1-dwbrk_1  |\u001b[0m     \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "\u001b[36malgo-1-dwbrk_1  |\u001b[0m     \"resource_config\": {\n",
      "\u001b[36malgo-1-dwbrk_1  |\u001b[0m         \"current_host\": \"algo-1-dwbrk\",\n",
      "\u001b[36malgo-1-dwbrk_1  |\u001b[0m         \"hosts\": [\n",
      "\u001b[36malgo-1-dwbrk_1  |\u001b[0m             \"algo-1-dwbrk\"\n",
      "\u001b[36malgo-1-dwbrk_1  |\u001b[0m         ]\n",
      "\u001b[36malgo-1-dwbrk_1  |\u001b[0m     },\n",
      "\u001b[36malgo-1-dwbrk_1  |\u001b[0m     \"user_entry_point\": \"train.py\"\n",
      "\u001b[36malgo-1-dwbrk_1  |\u001b[0m }\n",
      "\u001b[36malgo-1-dwbrk_1  |\u001b[0m \n",
      "\u001b[36malgo-1-dwbrk_1  |\u001b[0m Environment variables:\n",
      "\u001b[36malgo-1-dwbrk_1  |\u001b[0m \n",
      "\u001b[36malgo-1-dwbrk_1  |\u001b[0m SM_HOSTS=[\"algo-1-dwbrk\"]\n",
      "\u001b[36malgo-1-dwbrk_1  |\u001b[0m SM_NETWORK_INTERFACE_NAME=eth0\n",
      "\u001b[36malgo-1-dwbrk_1  |\u001b[0m SM_HPS={\"epochs\":200}\n",
      "\u001b[36malgo-1-dwbrk_1  |\u001b[0m SM_USER_ENTRY_POINT=train.py\n",
      "\u001b[36malgo-1-dwbrk_1  |\u001b[0m SM_FRAMEWORK_PARAMS={}\n",
      "\u001b[36malgo-1-dwbrk_1  |\u001b[0m SM_RESOURCE_CONFIG={\"current_host\":\"algo-1-dwbrk\",\"hosts\":[\"algo-1-dwbrk\"]}\n",
      "\u001b[36malgo-1-dwbrk_1  |\u001b[0m SM_INPUT_DATA_CONFIG={}\n",
      "\u001b[36malgo-1-dwbrk_1  |\u001b[0m SM_OUTPUT_DATA_DIR=/opt/ml/output/data\n",
      "\u001b[36malgo-1-dwbrk_1  |\u001b[0m SM_CHANNELS=[]\n",
      "\u001b[36malgo-1-dwbrk_1  |\u001b[0m SM_CURRENT_HOST=algo-1-dwbrk\n",
      "\u001b[36malgo-1-dwbrk_1  |\u001b[0m SM_MODULE_NAME=train\n",
      "\u001b[36malgo-1-dwbrk_1  |\u001b[0m SM_LOG_LEVEL=20\n",
      "\u001b[36malgo-1-dwbrk_1  |\u001b[0m SM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\n",
      "\u001b[36malgo-1-dwbrk_1  |\u001b[0m SM_INPUT_DIR=/opt/ml/input\n",
      "\u001b[36malgo-1-dwbrk_1  |\u001b[0m SM_INPUT_CONFIG_DIR=/opt/ml/input/config\n",
      "\u001b[36malgo-1-dwbrk_1  |\u001b[0m SM_OUTPUT_DIR=/opt/ml/output\n",
      "\u001b[36malgo-1-dwbrk_1  |\u001b[0m SM_NUM_CPUS=2\n",
      "\u001b[36malgo-1-dwbrk_1  |\u001b[0m SM_NUM_GPUS=0\n",
      "\u001b[36malgo-1-dwbrk_1  |\u001b[0m SM_MODEL_DIR=/opt/ml/model\n",
      "\u001b[36malgo-1-dwbrk_1  |\u001b[0m SM_MODULE_DIR=/opt/ml/code\n",
      "\u001b[36malgo-1-dwbrk_1  |\u001b[0m SM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{},\"current_host\":\"algo-1-dwbrk\",\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1-dwbrk\"],\"hyperparameters\":{\"epochs\":200},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"sagemaker-tennis-cpu-2020-07-04-15-34-21-570\",\"log_level\":20,\"master_hostname\":\"algo-1-dwbrk\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"/opt/ml/code\",\"module_name\":\"train\",\"network_interface_name\":\"eth0\",\"num_cpus\":2,\"num_gpus\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1-dwbrk\",\"hosts\":[\"algo-1-dwbrk\"]},\"user_entry_point\":\"train.py\"}\n",
      "\u001b[36malgo-1-dwbrk_1  |\u001b[0m SM_USER_ARGS=[\"--epochs\",\"200\"]\n",
      "\u001b[36malgo-1-dwbrk_1  |\u001b[0m SM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\n",
      "\u001b[36malgo-1-dwbrk_1  |\u001b[0m SM_HP_EPOCHS=200\n",
      "\u001b[36malgo-1-dwbrk_1  |\u001b[0m PYTHONPATH=/usr/local/bin:/usr/lib/python36.zip:/usr/lib/python3.6:/usr/lib/python3.6/lib-dynload:/usr/local/lib/python3.6/dist-packages:/usr/lib/python3/dist-packages\n",
      "\u001b[36malgo-1-dwbrk_1  |\u001b[0m \n",
      "\u001b[36malgo-1-dwbrk_1  |\u001b[0m Invoking script with the following command:\n",
      "\u001b[36malgo-1-dwbrk_1  |\u001b[0m \n",
      "\u001b[36malgo-1-dwbrk_1  |\u001b[0m /usr/bin/python -m train --epochs 200\n",
      "\u001b[36malgo-1-dwbrk_1  |\u001b[0m \n",
      "\u001b[36malgo-1-dwbrk_1  |\u001b[0m \n",
      "\u001b[36malgo-1-dwbrk_1  |\u001b[0m Found path: /opt/ml/code/Tennis_Linux_NoVis/Tennis.x86_64\n",
      "\u001b[36malgo-1-dwbrk_1  |\u001b[0m Mono path[0] = '/opt/ml/code/Tennis_Linux_NoVis/Tennis_Data/Managed'\n",
      "\u001b[36malgo-1-dwbrk_1  |\u001b[0m Mono config path = '/opt/ml/code/Tennis_Linux_NoVis/Tennis_Data/MonoBleedingEdge/etc'\n",
      "\u001b[36malgo-1-dwbrk_1  |\u001b[0m Preloaded 'libgrpc_csharp_ext.x64.so'\n",
      "\u001b[36malgo-1-dwbrk_1  |\u001b[0m Unable to preload the following plugins:\n",
      "\u001b[36malgo-1-dwbrk_1  |\u001b[0m \tlibgrpc_csharp_ext.x86.so\n",
      "\u001b[36malgo-1-dwbrk_1  |\u001b[0m PlayerPrefs - Creating folder: /root/.config/unity3d/Unity Technologies\n",
      "\u001b[36malgo-1-dwbrk_1  |\u001b[0m PlayerPrefs - Creating folder: /root/.config/unity3d/Unity Technologies/Unity Environment\n",
      "\u001b[36malgo-1-dwbrk_1  |\u001b[0m Logging to /root/.config/unity3d/Unity Technologies/Unity Environment/Player.log\n",
      "\u001b[36malgo-1-dwbrk_1  |\u001b[0m Episode 100 Average Score: 0.00\n",
      "\u001b[36malgo-1-dwbrk_1  |\u001b[0m Episode 200 Average Score: 0.00\n",
      "\u001b[36malgo-1-dwbrk_1  |\u001b[0m 200 training episodes completed.\n",
      "\u001b[36malgo-1-dwbrk_1  |\u001b[0m 0.00 average score.\n",
      "\u001b[36malgo-1-dwbrk_1  |\u001b[0m 1.23 minutes of training.\n",
      "\u001b[36malgo-1-dwbrk_1  |\u001b[0m 212.31 training objective.\n",
      "\u001b[36malgo-1-dwbrk_1  |\u001b[0m 2020-07-04 15:35:53,945 sagemaker-containers INFO     Reporting training SUCCESS\n",
      "\u001b[36mtmpl4u04c4__algo-1-dwbrk_1 exited with code 0\n",
      "\u001b[0mAborting on container exit...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to delete: /tmp/tmpl4u04c4_/algo-1-dwbrk Please remove it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Job Complete =====\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.estimator import Estimator\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "role = get_execution_role()\n",
    "estimator = Estimator(role=role,\n",
    "                      instance_count=1,\n",
    "                      instance_type='local',\n",
    "                      image_uri='rl-portfolio-optimization:latest',\n",
    "                      hyperparameters={'timesteps': 1000})\n",
    "\n",
    "estimator.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training on SageMaker\n",
    "Training a model on SageMaker with the Python SDK is done in a way that is similar to the way we trained it locally. This is done by changing our train_instance_type from `local` to one of the [supported EC2 instance types](https://aws.amazon.com/sagemaker/pricing/instance-types/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Locate the ECR image just built and pushed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "031118886020.dkr.ecr.us-east-1.amazonaws.com/sagemaker-tennis-cpu:latest\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "\n",
    "client = boto3.client('sts')\n",
    "account = client.get_caller_identity()['Account']\n",
    "region = boto3.Session().region_name\n",
    "ecr_image = '{}.dkr.ecr.{}.amazonaws.com/rl-portfolio-optimization:latest'.format(account, region)\n",
    "\n",
    "print(ecr_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submit the training job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-07-04 15:35:55 Starting - Starting the training job...\n",
      "2020-07-04 15:35:57 Starting - Launching requested ML instances......\n",
      "2020-07-04 15:37:11 Starting - Preparing the instances for training......\n",
      "2020-07-04 15:38:19 Downloading - Downloading input data\n",
      "2020-07-04 15:38:19 Training - Downloading the training image......\n",
      "2020-07-04 15:39:26 Training - Training image download completed. Training in progress..\u001b[34mbash: cannot set terminal process group (-1): Inappropriate ioctl for device\u001b[0m\n",
      "\u001b[34mbash: no job control in this shell\u001b[0m\n",
      "\u001b[34m2020-07-04 15:39:27,526 sagemaker-containers INFO     Imported framework sagemaker_pytorch_container.training\u001b[0m\n",
      "\u001b[34m2020-07-04 15:39:27,529 sagemaker-containers INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2020-07-04 15:39:27,542 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\u001b[0m\n",
      "\u001b[34m2020-07-04 15:39:27,543 sagemaker_pytorch_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[34m2020-07-04 15:39:27,544 sagemaker-containers INFO     Module train does not provide a setup.py. \u001b[0m\n",
      "\u001b[34mGenerating setup.py\u001b[0m\n",
      "\u001b[34m2020-07-04 15:39:27,544 sagemaker-containers INFO     Generating setup.cfg\u001b[0m\n",
      "\u001b[34m2020-07-04 15:39:27,544 sagemaker-containers INFO     Generating MANIFEST.in\u001b[0m\n",
      "\u001b[34m2020-07-04 15:39:27,544 sagemaker-containers INFO     Installing module with the following command:\u001b[0m\n",
      "\u001b[34m/usr/bin/python -m pip install . \u001b[0m\n",
      "\u001b[34mProcessing /opt/ml/code\u001b[0m\n",
      "\u001b[34mBuilding wheels for collected packages: train\n",
      "  Building wheel for train (setup.py): started\u001b[0m\n",
      "\u001b[34m  Building wheel for train (setup.py): finished with status 'done'\n",
      "  Created wheel for train: filename=train-1.0.0-py2.py3-none-any.whl size=45199378 sha256=316b095c6b28ee694397f0ff130ad0e21f4b5fee647bae96d77682cb01176305\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-58hoe3yc/wheels/95/c1/85/65aaf48b35aba88c6e896d2fd04a4b69f1cee0d81ea32993ca\u001b[0m\n",
      "\u001b[34mSuccessfully built train\u001b[0m\n",
      "\u001b[34mInstalling collected packages: train\u001b[0m\n",
      "\u001b[34mSuccessfully installed train-1.0.0\u001b[0m\n",
      "\u001b[34m2020-07-04 15:39:38,772 sagemaker-containers INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2020-07-04 15:39:38,785 sagemaker-containers INFO     Invoking user script\n",
      "\u001b[0m\n",
      "\u001b[34mTraining Env:\n",
      "\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {},\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"epochs\": 200\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {},\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"is_master\": true,\n",
      "    \"job_name\": \"sagemaker-tennis-cpu-2020-07-04-15-35-54-764\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"/opt/ml/code\",\n",
      "    \"module_name\": \"train\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 4,\n",
      "    \"num_gpus\": 0,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"train.py\"\u001b[0m\n",
      "\u001b[34m}\n",
      "\u001b[0m\n",
      "\u001b[34mEnvironment variables:\n",
      "\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"epochs\":200}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=train.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=train\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=4\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=0\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=/opt/ml/code\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"epochs\":200},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"sagemaker-tennis-cpu-2020-07-04-15-35-54-764\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"/opt/ml/code\",\"module_name\":\"train\",\"network_interface_name\":\"eth0\",\"num_cpus\":4,\"num_gpus\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"train.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--epochs\",\"200\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_HP_EPOCHS=200\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/usr/local/bin:/usr/lib/python36.zip:/usr/lib/python3.6:/usr/lib/python3.6/lib-dynload:/usr/local/lib/python3.6/dist-packages:/usr/lib/python3/dist-packages\n",
      "\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\n",
      "\u001b[0m\n",
      "\u001b[34m/usr/bin/python -m train --epochs 200\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[34mFound path: /opt/ml/code/Tennis_Linux_NoVis/Tennis.x86_64\u001b[0m\n",
      "\u001b[34mMono path[0] = '/opt/ml/code/Tennis_Linux_NoVis/Tennis_Data/Managed'\u001b[0m\n",
      "\u001b[34mMono config path = '/opt/ml/code/Tennis_Linux_NoVis/Tennis_Data/MonoBleedingEdge/etc'\u001b[0m\n",
      "\u001b[34mPreloaded 'libgrpc_csharp_ext.x64.so'\u001b[0m\n",
      "\u001b[34mUnable to preload the following plugins:\u001b[0m\n",
      "\u001b[34m#011libgrpc_csharp_ext.x86.so\u001b[0m\n",
      "\u001b[34mPlayerPrefs - Creating folder: /root/.config/unity3d/Unity Technologies\u001b[0m\n",
      "\u001b[34mPlayerPrefs - Creating folder: /root/.config/unity3d/Unity Technologies/Unity Environment\u001b[0m\n",
      "\u001b[34mLogging to /root/.config/unity3d/Unity Technologies/Unity Environment/Player.log\u001b[0m\n",
      "\u001b[34mEpisode 100 Average Score: 0.00\u001b[0m\n",
      "\n",
      "2020-07-04 15:40:53 Uploading - Uploading generated training model\n",
      "2020-07-04 15:40:53 Completed - Training job completed\n",
      "\u001b[34mEpisode 200 Average Score: 0.00\u001b[0m\n",
      "\u001b[34m200 training episodes completed.\u001b[0m\n",
      "\u001b[34m0.00 average score.\u001b[0m\n",
      "\u001b[34m1.07 minutes of training.\u001b[0m\n",
      "\u001b[34m210.69 training objective.\u001b[0m\n",
      "\u001b[34m2020-07-04 15:40:46,264 sagemaker-containers INFO     Reporting training SUCCESS\u001b[0m\n",
      "Training seconds: 162\n",
      "Billable seconds: 162\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.estimator import Estimator\n",
    "estimator = Estimator(role=role,\n",
    "                      instance_count=1,\n",
    "                      instance_type='ml.m4.xlarge',\n",
    "                      image_name=ecr_image,\n",
    "                      hyperparameters={'timesteps': 200})\n",
    "estimator.fit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p36",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

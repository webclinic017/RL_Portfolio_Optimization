{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning of Tennis Reinforcement Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook determines the best set of hyperparameters to solve the Tennis enviornment as quickly as possible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import necessary modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import boto3\n",
    "from IPython.display import Image\n",
    "from sagemaker import get_execution_role\n",
    "from sagemaker.estimator import Estimator\n",
    "from sagemaker.session import Session\n",
    "from sagemaker.tuner import IntegerParameter, CategoricalParameter, ContinuousParameter, HyperparameterTuner\n",
    "import shutil\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set local parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "instance_type = 'ml.m5.large'\n",
    "n_timesteps = 3000\n",
    "n_instances = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set the hyperparameters to optimize\n",
    "The following hyperparameters are read from the command line in [train.py](container/src/train.py).\n",
    "\n",
    "| Name        | Type  | Default | Description                        |\n",
    "|-------------|-------|---------|------------------------------------|\n",
    "| epochs      | int   |    2000 | number of total epochs to run      |\n",
    "| max_t       | int   |    1000 | max number of time steps per epoch |\n",
    "| fc1         | int   |     128 | size of 1st hidden layer           |\n",
    "| fc2         | int   |      64 | size of 2bd hidden layer           |\n",
    "| lr_actor    | float |   0.001 | initial learning rate for actor    |\n",
    "| lr_critic   | float |   0.001 | initial learning rate for critic   |\n",
    "| batch_size  | int   |     256 | mini batch size                    |\n",
    "| buffer_size | int   |  100000 | replay buffer size                 |\n",
    "| gamma       | float |     0.9 | discount factor                    |\n",
    "| tau         | float |   0.001 | soft update of target parameters   |\n",
    "| sigma       | float |    0.01 | OU Noise standard deviation        |\n",
    "\n",
    "Any of these could be tuned but we will down select to limit the search.    \n",
    "\n",
    "The hyperparameter tunner allow the hyperparameters to be defined as one of the following types. \n",
    "- `CategoricalParameter(list)` Categorical parameters need to take one value from a discrete set. \n",
    "- `ContinuousParameter(min, max)` Continuous parameters can take any real number value between the minimum and maximum value.\n",
    "- `IntegerParameter(min, max)` Integer parameters can take any integer value between the minimum and maximum value.\n",
    "\n",
    "_Note, if possible, it's almost always best to specify a value as the least restrictive type. For example, tuning learning rate as a continuous value between 0.01 and 0.2 is likely to yield a better result than tuning as a categorical parameter with values 0.01, 0.1, 0.15, or 0.2. Some parameters are categorical to maintain a power 2 structure and limit the search space._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameter_ranges = {\n",
    "    'fc1': CategoricalParameter([64, 128]),\n",
    "    'fc2': CategoricalParameter([32, 64]),\n",
    "    'lr_actor': ContinuousParameter(0.0001, 0.01),\n",
    "    'lr_critic': ContinuousParameter(0.0001, 0.01),\n",
    "    'batch_size': CategoricalParameter([128,256]),\n",
    "    'buffer_size': CategoricalParameter([10000,100000]),\n",
    "    'gamma': ContinuousParameter(0.85, 0.95),\n",
    "    'tau': ContinuousParameter(0.0001, 0.01),\n",
    "    'sigma': ContinuousParameter(0.001, 0.1),\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set the objective\n",
    "Next we'll specify the objective metric that we'd like to tune and its definition, which includes the regular expression (Regex) needed to extract that metric from the CloudWatch logs of the training job. In this particular case, our script emits the total trainging episodes and we will use it as the objective metric, we also set the objective_type to be 'Minimize', so that hyperparameter tuning seeks to minize the objective metric when searching for the best hyperparameter setting. By default, objective_type is set to 'Maximize'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "objective_metric_name = 'time to solve'\n",
    "objective_type = 'Minimize'\n",
    "metric_definitions = [{'Name': objective_metric_name,\n",
    "                       'Regex': '(\\S+) training objective.'}]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compile environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "031118886020.dkr.ecr.us-east-1.amazonaws.com/sagemaker-tennis-cpu:latest\n"
     ]
    }
   ],
   "source": [
    "role = get_execution_role()\n",
    "account = boto3.client('sts').get_caller_identity()['Account']\n",
    "region = boto3.Session().region_name\n",
    "image_name = '{}.dkr.ecr.{}.amazonaws.com/rl-portfolio-optimization:latest'.format(account, region)\n",
    "print(image_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create the base estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = Estimator(role=role,\n",
    "                  instance_count=n_instances,\n",
    "                  instance_type=instance_type,\n",
    "                  image_uri=image_name,\n",
    "                  hyperparameters={'timesteps': n_timesteps})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create the hyperparameter tuner object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner = HyperparameterTuner(estimator,\n",
    "                            objective_metric_name,\n",
    "                            hyperparameter_ranges,\n",
    "                            metric_definitions,\n",
    "                            max_jobs=100,\n",
    "                            max_parallel_jobs=10,\n",
    "                            objective_type=objective_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Perform the hyperparameter tuning\n",
    "After the hyperprameter tuning job is created, you should be able to describe the tuning job to see its progress in the next step, and you can go to SageMaker console -> `Training` -> `Hyperparameter tuning jobs` to see the progresss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...........................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................!\n"
     ]
    }
   ],
   "source": [
    "tuner.fit()\n",
    "tuner.wait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-07-04 21:37:03 Starting - Preparing the instances for training\n",
      "2020-07-04 21:37:03 Downloading - Downloading input data\n",
      "2020-07-04 21:37:03 Training - Training image download completed. Training in progress.\n",
      "2020-07-04 21:37:03 Uploading - Uploading generated training model\n",
      "2020-07-04 21:37:03 Completed - Training job completed\u001b[34mbash: cannot set terminal process group (-1): Inappropriate ioctl for device\u001b[0m\n",
      "\u001b[34mbash: no job control in this shell\u001b[0m\n",
      "\u001b[34m2020-07-04 21:30:45,539 sagemaker-containers INFO     Imported framework sagemaker_pytorch_container.training\u001b[0m\n",
      "\u001b[34m2020-07-04 21:30:45,540 sagemaker-containers INFO     Failed to parse hyperparameter _tuning_objective_metric value time to solve to Json.\u001b[0m\n",
      "\u001b[34mReturning the value itself\u001b[0m\n",
      "\u001b[34m2020-07-04 21:30:45,542 sagemaker-containers INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2020-07-04 21:30:45,560 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\u001b[0m\n",
      "\u001b[34m2020-07-04 21:30:46,983 sagemaker_pytorch_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[34m2020-07-04 21:30:46,984 sagemaker-containers INFO     Module train does not provide a setup.py. \u001b[0m\n",
      "\u001b[34mGenerating setup.py\u001b[0m\n",
      "\u001b[34m2020-07-04 21:30:46,985 sagemaker-containers INFO     Generating setup.cfg\u001b[0m\n",
      "\u001b[34m2020-07-04 21:30:46,985 sagemaker-containers INFO     Generating MANIFEST.in\u001b[0m\n",
      "\u001b[34m2020-07-04 21:30:46,985 sagemaker-containers INFO     Installing module with the following command:\u001b[0m\n",
      "\u001b[34m/usr/bin/python -m pip install . \u001b[0m\n",
      "\u001b[34mProcessing /opt/ml/code\u001b[0m\n",
      "\u001b[34mBuilding wheels for collected packages: train\n",
      "  Building wheel for train (setup.py): started\u001b[0m\n",
      "\u001b[34m  Building wheel for train (setup.py): finished with status 'done'\n",
      "  Created wheel for train: filename=train-1.0.0-py2.py3-none-any.whl size=45199378 sha256=45af56b758446fb14b3719a3a7d2aa370fe80355678cfb9214f75e02c1089d6e\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-z2eih611/wheels/95/c1/85/65aaf48b35aba88c6e896d2fd04a4b69f1cee0d81ea32993ca\u001b[0m\n",
      "\u001b[34mSuccessfully built train\u001b[0m\n",
      "\u001b[34mInstalling collected packages: train\u001b[0m\n",
      "\u001b[34mSuccessfully installed train-1.0.0\u001b[0m\n",
      "\u001b[34m2020-07-04 21:30:57,246 sagemaker-containers INFO     Failed to parse hyperparameter _tuning_objective_metric value time to solve to Json.\u001b[0m\n",
      "\u001b[34mReturning the value itself\u001b[0m\n",
      "\u001b[34m2020-07-04 21:30:57,249 sagemaker-containers INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2020-07-04 21:30:57,260 sagemaker-containers INFO     Invoking user script\n",
      "\u001b[0m\n",
      "\u001b[34mTraining Env:\n",
      "\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {},\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"sigma\": 0.013881149764204891,\n",
      "        \"lr_critic\": 0.0011363540815977902,\n",
      "        \"batch_size\": 256,\n",
      "        \"fc2\": 64,\n",
      "        \"fc1\": 128,\n",
      "        \"buffer_size\": 100000,\n",
      "        \"tau\": 0.007162249655166515,\n",
      "        \"lr_actor\": 0.0003734423831211392,\n",
      "        \"epochs\": 3000,\n",
      "        \"gamma\": 0.9123815613313767\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {},\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"is_master\": true,\n",
      "    \"job_name\": \"sagemaker-tennis-cpu-200704-1809-099-46b30d76\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"/opt/ml/code\",\n",
      "    \"module_name\": \"train\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 2,\n",
      "    \"num_gpus\": 0,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"train.py\"\u001b[0m\n",
      "\u001b[34m}\n",
      "\u001b[0m\n",
      "\u001b[34mEnvironment variables:\n",
      "\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"batch_size\":256,\"buffer_size\":100000,\"epochs\":3000,\"fc1\":128,\"fc2\":64,\"gamma\":0.9123815613313767,\"lr_actor\":0.0003734423831211392,\"lr_critic\":0.0011363540815977902,\"sigma\":0.013881149764204891,\"tau\":0.007162249655166515}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=train.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=train\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=2\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=0\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=/opt/ml/code\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"batch_size\":256,\"buffer_size\":100000,\"epochs\":3000,\"fc1\":128,\"fc2\":64,\"gamma\":0.9123815613313767,\"lr_actor\":0.0003734423831211392,\"lr_critic\":0.0011363540815977902,\"sigma\":0.013881149764204891,\"tau\":0.007162249655166515},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"sagemaker-tennis-cpu-200704-1809-099-46b30d76\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"/opt/ml/code\",\"module_name\":\"train\",\"network_interface_name\":\"eth0\",\"num_cpus\":2,\"num_gpus\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"train.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--batch_size\",\"256\",\"--buffer_size\",\"100000\",\"--epochs\",\"3000\",\"--fc1\",\"128\",\"--fc2\",\"64\",\"--gamma\",\"0.9123815613313767\",\"--lr_actor\",\"0.0003734423831211392\",\"--lr_critic\",\"0.0011363540815977902\",\"--sigma\",\"0.013881149764204891\",\"--tau\",\"0.007162249655166515\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_HP_SIGMA=0.013881149764204891\u001b[0m\n",
      "\u001b[34mSM_HP_LR_CRITIC=0.0011363540815977902\u001b[0m\n",
      "\u001b[34mSM_HP_BATCH_SIZE=256\u001b[0m\n",
      "\u001b[34mSM_HP_FC2=64\u001b[0m\n",
      "\u001b[34mSM_HP_FC1=128\u001b[0m\n",
      "\u001b[34mSM_HP_BUFFER_SIZE=100000\u001b[0m\n",
      "\u001b[34mSM_HP_TAU=0.007162249655166515\u001b[0m\n",
      "\u001b[34mSM_HP_LR_ACTOR=0.0003734423831211392\u001b[0m\n",
      "\u001b[34mSM_HP_EPOCHS=3000\u001b[0m\n",
      "\u001b[34mSM_HP_GAMMA=0.9123815613313767\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/usr/local/bin:/usr/lib/python36.zip:/usr/lib/python3.6:/usr/lib/python3.6/lib-dynload:/usr/local/lib/python3.6/dist-packages:/usr/lib/python3/dist-packages\n",
      "\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\n",
      "\u001b[0m\n",
      "\u001b[34m/usr/bin/python -m train --batch_size 256 --buffer_size 100000 --epochs 3000 --fc1 128 --fc2 64 --gamma 0.9123815613313767 --lr_actor 0.0003734423831211392 --lr_critic 0.0011363540815977902 --sigma 0.013881149764204891 --tau 0.007162249655166515\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[34mFound path: /opt/ml/code/Tennis_Linux_NoVis/Tennis.x86_64\u001b[0m\n",
      "\u001b[34mMono path[0] = '/opt/ml/code/Tennis_Linux_NoVis/Tennis_Data/Managed'\u001b[0m\n",
      "\u001b[34mMono config path = '/opt/ml/code/Tennis_Linux_NoVis/Tennis_Data/MonoBleedingEdge/etc'\u001b[0m\n",
      "\u001b[34mPreloaded 'libgrpc_csharp_ext.x64.so'\u001b[0m\n",
      "\u001b[34mUnable to preload the following plugins:\u001b[0m\n",
      "\u001b[34m#011libgrpc_csharp_ext.x86.so\u001b[0m\n",
      "\u001b[34mPlayerPrefs - Creating folder: /root/.config/unity3d/Unity Technologies\u001b[0m\n",
      "\u001b[34mPlayerPrefs - Creating folder: /root/.config/unity3d/Unity Technologies/Unity Environment\u001b[0m\n",
      "\u001b[34mLogging to /root/.config/unity3d/Unity Technologies/Unity Environment/Player.log\u001b[0m\n",
      "\u001b[34mEpisode 100 Average Score: 0.00\u001b[0m\n",
      "\u001b[34mEpisode 200 Average Score: 0.02\u001b[0m\n",
      "\u001b[34mEpisode 300 Average Score: 0.11\u001b[0m\n",
      "\u001b[34mEnvironment solved in 390 episodes!  Average Score: 0.53\u001b[0m\n",
      "\u001b[34m390 training episodes completed.\u001b[0m\n",
      "\u001b[34m0.53 average score.\u001b[0m\n",
      "\u001b[34m5.87 minutes of training.\u001b[0m\n",
      "\u001b[34m-79.09 training objective.\u001b[0m\n",
      "\u001b[34m2020-07-04 21:36:51,774 sagemaker-containers INFO     Reporting training SUCCESS\u001b[0m\n",
      "Training seconds: 437\n",
      "Billable seconds: 437\n"
     ]
    }
   ],
   "source": [
    "best_parameters = tuner.best_estimator().hyperparameters()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best model = sagemaker-tennis-cpu-200704-1809-099-46b30d76.\n",
      "\tfc1 = 128\n",
      "\tfc2 = 64\n",
      "\tlr_actor = 0.0003734423831211392\n",
      "\tlr_critic = 0.0011363540815977902\n",
      "\tbatch_size = 256\n",
      "\tbuffer_size = 100000\n",
      "\tgamma = 0.9123815613313767\n",
      "\ttau = 0.007162249655166515\n",
      "\tsigma = 0.013881149764204891\n"
     ]
    }
   ],
   "source": [
    "best_name = tuner.best_training_job()\n",
    "print('\\nBest model = {}.'.format(best_name))\n",
    "for name in hyperparameter_ranges.keys():\n",
    "    print('\\t{} = {}'.format(name, best_parameters[name]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compare optimal hyperparameters to manually optimized values.\n",
    "| Name        | Type  | Default | Description                        |\n",
    "|-------------|-------|---------|------------------------------------|\n",
    "| fc1         | int   |     128 | size of 1st hidden layer           |\n",
    "| fc2         | int   |      64 | size of 2bd hidden layer           |\n",
    "| lr_actor    | float |   0.001 | initial learning rate for actor    |\n",
    "| lr_critic   | float |   0.001 | initial learning rate for critic   |\n",
    "| batch_size  | int   |     256 | mini batch size                    |\n",
    "| buffer_size | int   |  100000 | replay buffer size                 |\n",
    "| gamma       | float |     0.9 | discount factor                    |\n",
    "| tau         | float |   0.001 | soft update of target parameters   |\n",
    "| sigma       | float |    0.01 | OU Noise standard deviation        |"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "notice": "Copyright 2018 Amazon.com, Inc. or its affiliates. All Rights Reserved. Licensed under the Apache License, Version 2.0 (the \"License\"). You may not use this file except in compliance with the License. A copy of the License is located at http://aws.amazon.com/apache2.0/ or in the \"license\" file accompanying this file. This file is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License.",
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
